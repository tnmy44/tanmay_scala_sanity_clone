{"initCode":"import org.apache.spark.sql.expressions.Window\nimport org.apache.spark.sql.functions._\n\nvar int_value = 10\nvar string_value = \"string value\"\nval colors = Map(\"red\" -> \"#FF0000\", \"azure\" -> \"#F0FFFF\", \"peru\" -> \"#CD853F\")\nval nums: Map[Int, Int] = Map()\nval fruit = Set(\"apples\", \"oranges\", \"pears\")\nval t = (4,3,2,1)\nval sum = t._1 + t._2 + t._3 + t._4\nval ita = Iterator(20,40,2,50,69, 90)\nval itb = Iterator(20,40,2,50,69, 90)","code":"udf((s: String) => s.length)\n// udf((column: String, windowSize: Int) => {\n//   val windowSpec = Window.orderBy(\"timestamp\").rowsBetween(-windowSize / 2, windowSize / 2)\n//   val df = Seq((1, \"a\", 10.0), (2, \"b\", 20.0), (3, \"c\", 30.0), (4, \"d\", 40.0)).toDF(\"id\", \"name\", \"value\")\n//   df.withColumn(\"moving_avg\", avg(column).over(windowSpec)).select(\"id\").count()\n// })"}